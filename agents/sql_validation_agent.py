

# # agents/sql_validation_agent.py

# from state.state_schema import AgentState
# from utils.gemini_client import gemini_chat
# import re
# import textwrap

# def sql_validation_agent(state: AgentState) -> AgentState:
#     if not state.display_preview:
#         state.error = "‚ùå No SQL query available to validate."
#         return state

#     sql = state.display_preview
#     column_names = state.column_names or []
#     original_names = state.original_names or []

#     # Static validation (quoted column correctness, etc.)
#     issues = []
#     used_columns = re.findall(r'"(.+?)"', sql)
#     for col in used_columns:
#         if col not in original_names:
#             clean_col = col.strip()
#             if clean_col in column_names:
#                 issues.append(f"‚ö†Ô∏è Column '{col}' likely meant '{clean_col}'")

#     # Prompt to LLM for validation + explanation
#     prompt = textwrap.dedent(f"""
#     You are a PostgreSQL code reviewer and business analyst.

#     A user asked a question: 
#     "{state.raw_text}"

#     The SQL generated for it is:
#     {sql}

#     Table: {state.table_name}
#     Schema Columns: {column_names}

#     Step 1: SQL Validation
#     - Check for correct table and column usage
#     - Check for syntax issues
#     - Flag any potential logical errors (e.g. comparing with NULL, unquoted strings, unsafe TO_DATE usage)

#     Step 2: Business Explanation
#     - What insight is this query trying to extract?
#     - Why might this be useful for an analyst or decision-maker?
#     - Is the logic sufficient to support that business goal?
#     - Prescriptive Analytics or predictive analytics as per the answer generated by the query and the user asked query
    

#     Respond with:
#     {{
#       "validation": "...",
#       "explanation": "..."
#     }}
#     ONLY return valid JSON object. No markdown.
#     """)

#     try:
#         print("\nü§ñ Agent: ‚úÖ SQL_Validation")
#         print(f"üîπ Input: table_name={state.table_name}, question={state.raw_text}")
#         llm_response = gemini_chat(prompt)
#         cleaned = re.sub(r"^```json|```$", "", llm_response.strip()).strip()
#         parsed = eval(cleaned) if cleaned.startswith("{") else {}

#         # Programmatic validation details first
#         validation_text = "\n".join([
#             "Programmatic Checks:",
#             *issues
#         ])
#         llm_validation = parsed.get("validation", "").strip()
#         explanation = parsed.get("explanation", "").strip()

#         # Store in state
#         state.validation_report = f"{validation_text}\n\nLLM Validation:\n{llm_validation}".strip()
#         state.explanation_report = explanation
#         return state

#     except Exception as e:
#         state.error = f"‚ùå Validation failed: {str(e)}"
#         return state

# agents/sql_validation_agent.py

from state.state_schema import AgentState
from utils.gemini_client import gemini_chat
import re
import textwrap
import json

def sql_validation_agent(state: AgentState) -> AgentState:
    if not state.display_preview:
        state.error = "‚ùå No SQL query available to validate."
        return state

    sql = state.display_preview
    column_names = state.column_names or []
    original_names = state.original_names or []

    print("\nü§ñ Agent: ‚úÖ SQL_Validation")
    print(f"üîπ Input: table_name={state.table_name}, question={state.raw_text}")

    # Static checks: unquoted/mismatched column names
    issues = []
    used_columns = re.findall(r'"(.+?)"', sql)
    for col in used_columns:
        if col not in original_names:
            clean_col = col.strip()
            if clean_col in column_names:
                issues.append(f"‚ö†Ô∏è Column '{col}' likely meant '{clean_col}'")
            else:
                issues.append(f"‚ö†Ô∏è Unknown column used: '{col}'")

    # LLM prompt
    prompt = textwrap.dedent(f"""
    You are a PostgreSQL code reviewer and SAP data analyst.

    Analyze the following query in two stages.

    --- QUESTION ---
    {state.raw_text}

    --- SQL ---
    {sql}

    --- SCHEMA COLUMNS ---
    {column_names}

    STEP 1: Validation
    - Validate syntax
    - Validate use of columns and table
    - Catch issues like unquoted strings, unsafe TO_DATE usage, comparison with NULL

    STEP 2: Explanation
    - What does the query intend to do?
    - What insight does it provide?
    - Is it descriptive, diagnostic, prescriptive, or predictive analytics?
    - How should a business user interpret the results?

    Format your output as **strict valid JSON object**, with:
    {{
      "validation": "<clear step-by-step findings>",
      "explanation": "<plain-language summary for business stakeholders>"
    }}
    Output only JSON ‚Äî no markdown, no comments.
    """)

    try:
        llm_response = gemini_chat(prompt)
        cleaned = re.sub(r"^```json|```$", "", llm_response.strip()).strip()

        parsed = json.loads(cleaned)
        llm_validation = parsed.get("validation", "").strip()
        explanation = parsed.get("explanation", "").strip()

        # Merge with static findings
        validation_text = "\n".join([
            "Programmatic Checks:",
            *issues,
            "\nLLM Validation:",
            llm_validation or "No validation provided by model."
        ])

        state.validation_report = validation_text.strip()
        state.explanation_report = explanation or "No explanation provided by model."
        return state

    except Exception as e:
        state.error = f"‚ùå Validation failed: {str(e)}"
        return state
